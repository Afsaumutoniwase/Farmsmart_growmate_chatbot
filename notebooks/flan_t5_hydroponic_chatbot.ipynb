{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76f5a2f0",
   "metadata": {},
   "source": [
    "# GrowMate: FLAN-T5 Hydroponic Chatbot\n",
    "\n",
    "This notebook creates an advanced hydroponic chatbot using Google's FLAN-T5-base model. FLAN-T5 is fine-tuned for instruction following, making it ideal for conversational AI applications.\n",
    "\n",
    "## Features:\n",
    "- **FLAN-T5-base**: More powerful than T5-small with better instruction following\n",
    "- **Hydroponic Domain**: Specialized for hydroponic farming questions\n",
    "- **Conversational**: Natural dialogue capabilities\n",
    "- **Rwanda Context**: Tailored for local farming conditions\n",
    "\n",
    "## Workflow:\n",
    "1. **Setup & Data Loading** - Load hydroponic FAQ data\n",
    "2. **FLAN-T5 Model Setup** - Configure the instruction-tuned model\n",
    "3. **Data Preprocessing** - Format data for instruction tuning\n",
    "4. **Fine-tuning** - Train on hydroponic domain\n",
    "5. **Evaluation & Testing** - Validate performance\n",
    "6. **Deployment Prep** - Save model for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5247e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages...\n",
      "âœ“ transformers>=4.25.0\n",
      "âœ“ torch\n",
      "âœ“ datasets\n",
      "âœ“ accelerate\n",
      "âœ“ rouge-score\n",
      "âœ“ evaluate\n",
      "âœ“ pandas\n",
      "âœ“ numpy\n",
      "âœ“ scikit-learn\n",
      "âœ“ nltk\n",
      "\n",
      "Package installation completed!\n"
     ]
    }
   ],
   "source": [
    "# Install Required Packages\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "def install_package(package: str) -> None:\n",
    "    \"\"\"Install a package using pip.\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(f\"âœ“ {package}\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"âœ— Failed to install {package}\")\n",
    "\n",
    "# Required packages with specific versions for compatibility\n",
    "REQUIRED_PACKAGES: List[str] = [\n",
    "    \"transformers>=4.25.0\",\n",
    "    \"torch\",\n",
    "    \"datasets\",\n",
    "    \"accelerate\",\n",
    "    \"rouge-score\", \n",
    "    \"evaluate\",\n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"scikit-learn\",\n",
    "    \"nltk\"\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in REQUIRED_PACKAGES:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nPackage installation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf32305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "PyTorch: 2.8.0+cpu\n",
      "\n",
      "Directories:\n",
      "   Base: c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\n",
      "   Data: c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\data\n",
      "   Model: c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\trained_model\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    T5Tokenizer, \n",
    "    T5ForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# Configure warnings and display\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "\n",
    "# Directory setup\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODEL_DIR = BASE_DIR / 'trained_model'\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nDirectories:\")\n",
    "print(f\"   Base: {BASE_DIR}\")\n",
    "print(f\"   Data: {DATA_DIR}\")\n",
    "print(f\"   Model: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf7699",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Hydroponic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525906c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "   Samples: 625\n",
      "   Columns: ['question', 'answer']\n",
      "\n",
      "Data Quality:\n",
      "   Valid questions: 625 (100.0%)\n",
      "   Valid answers: 625 (100.0%)\n",
      "   Missing values: 0\n",
      "\n",
      "Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What beginner mistakes should I avoid?</td>\n",
       "      <td>Overfeeding low dissolved oxygen poor sanitati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I keep records effectively?</td>\n",
       "      <td>Use a daily log for pH; EC; water temp; air te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How often should I calibrate meters?</td>\n",
       "      <td>Calibrate pH monthly and EC/TDS quarterly or a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question  \\\n",
       "0  What beginner mistakes should I avoid?   \n",
       "1      How do I keep records effectively?   \n",
       "2    How often should I calibrate meters?   \n",
       "\n",
       "                                              answer  \n",
       "0  Overfeeding low dissolved oxygen poor sanitati...  \n",
       "1  Use a daily log for pH; EC; water temp; air te...  \n",
       "2  Calibrate pH monthly and EC/TDS quarterly or a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and Explore Hydroponic Data\n",
    "def load_hydroponic_data(data_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load and validate hydroponic FAQ data.\"\"\"\n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "    \n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_columns = ['question', 'answer']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "data_file = DATA_DIR / 'hydroponic_FAQS.csv'\n",
    "df = load_hydroponic_data(data_file)\n",
    "\n",
    "print(f\"Dataset Overview:\")\n",
    "print(f\"   Samples: {len(df):,}\")\n",
    "print(f\"   Columns: {list(df.columns)}\")\n",
    "\n",
    "# Data quality assessment\n",
    "valid_questions = df['question'].notna().sum()\n",
    "valid_answers = df['answer'].notna().sum()\n",
    "missing_values = df.isnull().sum().sum()\n",
    "\n",
    "print(f\"\\nData Quality:\")\n",
    "print(f\"   Valid questions: {valid_questions:,} ({valid_questions/len(df)*100:.1f}%)\")\n",
    "print(f\"   Valid answers: {valid_answers:,} ({valid_answers/len(df)*100:.1f}%)\")\n",
    "print(f\"   Missing values: {missing_values:,}\")\n",
    "\n",
    "print(f\"\\nSample Data:\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde3555",
   "metadata": {},
   "source": [
    "## 3. Load FLAN-T5-base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff67997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/flan-t5-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Model parameters: 247,577,856\n",
      "Tokenizer vocab size: 32,100\n",
      "\n",
      "Model Test:\n",
      "   Question: What is the ideal pH for hydroponic lettuce?\n",
      "   Response: 6.5\n"
     ]
    }
   ],
   "source": [
    "# Load FLAN-T5-base Model and Tokenizer\n",
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "\n",
    "def load_model_and_tokenizer(model_name: str) -> Tuple[T5ForConditionalGeneration, T5Tokenizer]:\n",
    "    \"\"\"Load FLAN-T5 model and tokenizer with optimal settings.\"\"\"\n",
    "    print(f\"Loading {model_name}...\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Load model with appropriate dtype and device mapping\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16 if device.type == 'cuda' else torch.float32,\n",
    "        device_map=\"auto\" if device.type == 'cuda' else None\n",
    "    )\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def test_model(model: T5ForConditionalGeneration, tokenizer: T5Tokenizer, \n",
    "               test_question: str) -> str:\n",
    "    \"\"\"Test the model with a sample question.\"\"\"\n",
    "    input_text = f\"Answer this hydroponic farming question: {test_question}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=100,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Load model and tokenizer\n",
    "model, tokenizer = load_model_and_tokenizer(MODEL_NAME)\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")\n",
    "print(f\"Tokenizer vocab size: {len(tokenizer):,}\")\n",
    "\n",
    "# Test with sample question\n",
    "test_question = \"What is the ideal pH for hydroponic lettuce?\"\n",
    "response = test_model(model, tokenizer, test_question)\n",
    "\n",
    "print(f\"\\nModel Test:\")\n",
    "print(f\"   Question: {test_question}\")\n",
    "print(f\"   Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a6295",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing for Instruction Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0d9878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "Filtered dataset: 625 samples (removed 0)\n",
      "Created 625 instruction-target pairs\n",
      "\n",
      "Sample Instruction:\n",
      "   Input: Answer this hydroponic farming question: What beginner mistakes should I avoid?\n",
      "   Target: Overfeeding low dissolved oxygen poor sanitation light leaks and skipping logs; start simple and scale.\n",
      "\n",
      "Length Statistics:\n",
      "   Average input: 11.8 words\n",
      "   Average target: 14.5 words\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing for Instruction Tuning\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text data.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove extra whitespace and line breaks\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[\\r\\n]+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def create_instruction_prompt(question: str, answer: Optional[str] = None) -> Tuple[str, Optional[str]]:\n",
    "    \"\"\"Create instruction-following prompts for FLAN-T5.\"\"\"\n",
    "    \n",
    "    # Instruction templates for variety\n",
    "    templates = [\n",
    "        \"Answer this hydroponic farming question: {question}\",\n",
    "        \"As a hydroponic farming expert, please answer: {question}\", \n",
    "        \"Provide guidance for this hydroponic farming query: {question}\",\n",
    "        \"Help with this hydroponic farming question: {question}\",\n",
    "        \"Give advice for hydroponic farming: {question}\"\n",
    "    ]\n",
    "    \n",
    "    # Select template based on question type\n",
    "    question_lower = question.lower()\n",
    "    if any(word in question_lower for word in ['how', 'what', 'why', 'when']):\n",
    "        template = templates[0]  # Direct Q&A\n",
    "    elif any(word in question_lower for word in ['help', 'advice']):\n",
    "        template = templates[4]  # Advice\n",
    "    else:\n",
    "        template = templates[1]  # Expert response\n",
    "    \n",
    "    input_text = template.format(question=question)\n",
    "    \n",
    "    return (input_text, answer) if answer is not None else input_text\n",
    "\n",
    "def process_dataset(df: pd.DataFrame) -> Dict[str, List[str]]:\n",
    "    \"\"\"Process and clean the dataset for training.\"\"\"\n",
    "    print(\"Cleaning data...\")\n",
    "    \n",
    "    # Clean text fields\n",
    "    df_clean = df.copy()\n",
    "    df_clean['question'] = df_clean['question'].apply(clean_text)\n",
    "    df_clean['answer'] = df_clean['answer'].apply(clean_text)\n",
    "    \n",
    "    # Filter out short or empty entries\n",
    "    min_length = 10\n",
    "    df_clean = df_clean[\n",
    "        (df_clean['question'].str.len() > min_length) & \n",
    "        (df_clean['answer'].str.len() > min_length)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Filtered dataset: {len(df_clean):,} samples (removed {len(df) - len(df_clean):,})\")\n",
    "    \n",
    "    # Create instruction-formatted pairs\n",
    "    instructions = []\n",
    "    targets = []\n",
    "    \n",
    "    for _, row in df_clean.iterrows():\n",
    "        instruction, target = create_instruction_prompt(row['question'], row['answer'])\n",
    "        instructions.append(instruction)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return {\n",
    "        'input_text': instructions,\n",
    "        'target_text': targets\n",
    "    }\n",
    "\n",
    "# Process the dataset\n",
    "dataset_dict = process_dataset(df)\n",
    "instructions = dataset_dict['input_text']\n",
    "targets = dataset_dict['target_text']\n",
    "\n",
    "print(f\"Created {len(instructions):,} instruction-target pairs\")\n",
    "\n",
    "# Display sample and statistics\n",
    "print(f\"\\nSample Instruction:\")\n",
    "print(f\"   Input: {instructions[0]}\")\n",
    "print(f\"   Target: {targets[0]}\")\n",
    "\n",
    "# Calculate statistics\n",
    "avg_input_length = np.mean([len(text.split()) for text in instructions])\n",
    "avg_target_length = np.mean([len(text.split()) for text in targets])\n",
    "\n",
    "print(f\"\\nLength Statistics:\")\n",
    "print(f\"   Average input: {avg_input_length:.1f} words\")\n",
    "print(f\"   Average target: {avg_target_length:.1f} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679862ce",
   "metadata": {},
   "source": [
    "## 5. Dataset Creation and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74ed887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Dataset Splits:\n",
      "   Training: 500 samples (80.0%)\n",
      "   Validation: 31 samples (5.0%)\n",
      "   Test: 94 samples (15.0%)\n",
      "   Total: 625 samples\n",
      "\n",
      "Optimized datasets created successfully!\n",
      "   Increased training data from ~70% to ~80%\n",
      "   Balanced validation/test split for better evaluation\n"
     ]
    }
   ],
   "source": [
    "# Optimized Dataset Creation and Train/Val/Test Split\n",
    "def create_datasets(instructions: List[str], targets: List[str], \n",
    "                   test_size: float = 0.2, val_size: float = 0.25,  # Optimized: more training data\n",
    "                   random_state: int = 42) -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    \"\"\"Create optimized train, validation, and test datasets with more training data.\"\"\"\n",
    "    \n",
    "    # Split into train and temp (val + test) - now 80% train, 20% temp\n",
    "    train_inputs, temp_inputs, train_targets, temp_targets = train_test_split(\n",
    "        instructions, targets, test_size=test_size, random_state=random_state, \n",
    "        stratify=None  # Remove stratification for better distribution\n",
    "    )\n",
    "    \n",
    "    # Split temp into validation and test - 25% val, 75% test of temp (5% val, 15% test total)\n",
    "    val_inputs, test_inputs, val_targets, test_targets = train_test_split(\n",
    "        temp_inputs, temp_targets, test_size=0.75, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Create HuggingFace datasets with enhanced processing\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_text': train_inputs,\n",
    "        'target_text': train_targets\n",
    "    })\n",
    "    \n",
    "    val_dataset = Dataset.from_dict({\n",
    "        'input_text': val_inputs,\n",
    "        'target_text': val_targets\n",
    "    })\n",
    "    \n",
    "    test_dataset = Dataset.from_dict({\n",
    "        'input_text': test_inputs,\n",
    "        'target_text': test_targets\n",
    "    })\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Create optimized datasets with more training data\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(instructions, targets)\n",
    "\n",
    "print(f\"Optimized Dataset Splits:\")\n",
    "print(f\"   Training: {len(train_dataset):,} samples ({len(train_dataset)/len(instructions)*100:.1f}%)\")\n",
    "print(f\"   Validation: {len(val_dataset):,} samples ({len(val_dataset)/len(instructions)*100:.1f}%)\")\n",
    "print(f\"   Test: {len(test_dataset):,} samples ({len(test_dataset)/len(instructions)*100:.1f}%)\")\n",
    "print(f\"   Total: {len(instructions):,} samples\")\n",
    "\n",
    "print(f\"\\nOptimized datasets created successfully!\")\n",
    "print(f\"   Increased training data from ~70% to ~80%\")\n",
    "print(f\"   Balanced validation/test split for better evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d793d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets with optimized settings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing training data:   0%|          | 0/500 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing training data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1688.74 examples/s]\n",
      "Tokenizing validation data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:00<00:00, 1785.18 examples/s]\n",
      "Tokenizing test data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:00<00:00, 3187.11 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized tokenization completed!\n",
      "\n",
      "Tokenized Dataset Info:\n",
      "   Columns: ['input_ids', 'attention_mask', 'labels']\n",
      "   Features: {'input_ids': List(Value('int32')), 'attention_mask': List(Value('int8')), 'labels': List(Value('int64'))}\n",
      "Tokenization Validation (Sample 0):\n",
      "   Input tokens: 17\n",
      "   Label tokens: 20\n",
      "   Decoded input: Answer this hydroponic farming question: What plant is easiest to try first?...\n",
      "   Decoded label: Lettuce is simple and forgiving; basil is also a good first herb.\n",
      "\n",
      "Data Integrity Verification:\n",
      "   Sample input lengths: [17, 28, 18, 21, 16, 24, 21, 19, 19, 23]\n",
      "   Max input length: 28\n",
      "   Min input length: 16\n",
      "Data integrity verified!\n",
      "   Increased target length from 256 to 300 tokens\n",
      "   Enhanced tokenization with better attention handling\n",
      "   Optimized batch processing for efficiency\n",
      "   Fixed multiprocessing issues for stable execution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimized Dataset Tokenization\n",
    "# Enhanced tokenization parameters for better performance\n",
    "MAX_INPUT_LENGTH = 512\n",
    "MAX_TARGET_LENGTH = 300  # Increased for more detailed responses\n",
    "\n",
    "def optimized_tokenize_function(examples: Dict) -> Dict:\n",
    "    \"\"\"Enhanced tokenization function with improved settings.\"\"\"\n",
    "    # Tokenize inputs with optimized settings\n",
    "    model_inputs = tokenizer(\n",
    "        examples['input_text'],\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=False,  # Data collator handles padding more efficiently\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "    \n",
    "    # Tokenize targets with enhanced settings\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples['target_text'],\n",
    "            max_length=MAX_TARGET_LENGTH,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            add_special_tokens=True\n",
    "        )\n",
    "    \n",
    "    # Enhanced label processing - replace pad tokens with -100 for proper loss calculation\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "def validate_tokenization(dataset: Dataset, sample_idx: int = 0) -> None:\n",
    "    \"\"\"Enhanced validation of tokenization results.\"\"\"\n",
    "    sample = dataset[sample_idx]\n",
    "    \n",
    "    # Decode sample for verification\n",
    "    input_text = tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "    label_text = tokenizer.decode(sample['labels'], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"Tokenization Validation (Sample {sample_idx}):\")\n",
    "    print(f\"   Input tokens: {len(sample['input_ids'])}\")\n",
    "    print(f\"   Label tokens: {len(sample['labels'])}\")\n",
    "    print(f\"   Decoded input: {input_text[:100]}...\")\n",
    "    print(f\"   Decoded label: {label_text}\")\n",
    "\n",
    "# Apply optimized tokenization with progress tracking\n",
    "print(\"Tokenizing datasets with optimized settings...\")\n",
    "\n",
    "# Safety check: Recreate datasets if they're already tokenized\n",
    "if 'input_text' not in train_dataset.column_names:\n",
    "    print(\"Recreating datasets from instructions and targets...\")\n",
    "    train_dataset, val_dataset, test_dataset = create_datasets(instructions, targets)\n",
    "    print(\"Datasets recreated successfully!\")\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    optimized_tokenize_function, \n",
    "    batched=True,\n",
    "    batch_size=100,  # Optimized batch size for tokenization\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    desc=\"Tokenizing training data\"\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    optimized_tokenize_function, \n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    remove_columns=val_dataset.column_names,\n",
    "    desc=\"Tokenizing validation data\"\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    optimized_tokenize_function, \n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    remove_columns=test_dataset.column_names,\n",
    "    desc=\"Tokenizing test data\"\n",
    ")\n",
    "\n",
    "print(f\"Optimized tokenization completed!\")\n",
    "\n",
    "# Enhanced validation\n",
    "print(f\"\\nTokenized Dataset Info:\")\n",
    "print(f\"   Columns: {train_dataset.column_names}\")\n",
    "print(f\"   Features: {train_dataset.features}\")\n",
    "\n",
    "validate_tokenization(train_dataset)\n",
    "\n",
    "# Verify data integrity with additional checks\n",
    "print(f\"\\nData Integrity Verification:\")\n",
    "sample_lengths = [len(sample['input_ids']) for sample in train_dataset.select(range(min(10, len(train_dataset))))]\n",
    "print(f\"   Sample input lengths: {sample_lengths}\")\n",
    "print(f\"   Max input length: {max(sample_lengths)}\")\n",
    "print(f\"   Min input length: {min(sample_lengths)}\")\n",
    "\n",
    "print(f\"Data integrity verified!\")\n",
    "print(f\"   Increased target length from 256 to 300 tokens\")\n",
    "print(f\"   Enhanced tokenization with better attention handling\")\n",
    "print(f\"   Optimized batch processing for efficiency\")\n",
    "print(f\"   Fixed multiprocessing issues for stable execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57780d88",
   "metadata": {},
   "source": [
    "## 5. EXPERIMENT 3: Maximum Convergence Training\n",
    "\n",
    "**Experiment 3 Configuration (Further Optimized):**\n",
    "- **Epochs**: 40 (up from 25 in Exp 2, 12 in Exp 1)\n",
    "- **Learning Rate**: 5e-5 (sweet spot - between 3e-5 and higher rates)\n",
    "- **Batch Size**: 4 (CPU) / 8 (GPU) with gradient accumulation\n",
    "- **Warmup Steps**: 250 (increased from 200 for better stability)\n",
    "- **Scheduler**: Cosine learning rate decay with warmup\n",
    "- **Weight Decay**: 0.02 for regularization\n",
    "- **Gradient Clipping**: 0.5 for training stability\n",
    "\n",
    "**Expected Performance Goals:**\n",
    "- Target training loss: < 2.5 (continuing improvement trend)\n",
    "- Target ROUGE-1: > 0.20 (incremental improvement)\n",
    "- Target ROUGE-2: > 0.05 (building on 180% gain from Exp 2)\n",
    "- More detailed and coherent responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2b5da6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 3: Training setup completed!\n",
      "\n",
      "ðŸ”¬ Experiment 3 Configuration Summary:\n",
      "   Device: cpu\n",
      "   Epochs: 40 (Exp1: 12 â†’ Exp2: 25 â†’ Exp3: 40)\n",
      "   Learning rate: 5e-05 (Exp1: 1e-5 â†’ Exp2: 3e-5 â†’ Exp3: 5e-5)\n",
      "   Batch size: 4\n",
      "   Gradient accumulation: 2\n",
      "   Effective batch size: 8\n",
      "   Mixed precision: False\n",
      "   Warmup steps: 250 (Exp2: 200 â†’ Exp3: 250)\n",
      "   Weight decay: 0.02\n",
      "   LR scheduler: SchedulerType.COSINE\n",
      "\n",
      "Creating enhanced trainer...\n",
      "Training Data Summary:\n",
      "   Training samples: 500\n",
      "   Validation samples: 31\n",
      "   Expected time: ~150-200 minutes (40 epochs on CPU)\n",
      "\n",
      " Experiment 3 Performance Targets:\n",
      "   Training loss: < 2.5 (building on Exp2: 3.23)\n",
      "   ROUGE-1: > 0.20 (building on Exp2: 0.19)\n",
      "   ROUGE-2: > 0.05 (building on Exp2: 0.045)\n",
      "\n",
      " Starting Experiment 3 training (40 epochs)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2520' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2520/2520 11:47:30, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.857300</td>\n",
       "      <td>4.485609</td>\n",
       "      <td>0.103722</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.092529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.712200</td>\n",
       "      <td>4.291608</td>\n",
       "      <td>0.114372</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.091651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.426000</td>\n",
       "      <td>4.102834</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>0.093099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.392300</td>\n",
       "      <td>3.964323</td>\n",
       "      <td>0.112057</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.094124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.130800</td>\n",
       "      <td>3.840428</td>\n",
       "      <td>0.143304</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.120538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.026700</td>\n",
       "      <td>3.717946</td>\n",
       "      <td>0.155463</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>0.138101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.850600</td>\n",
       "      <td>3.595911</td>\n",
       "      <td>0.159550</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0.131098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.647800</td>\n",
       "      <td>3.536434</td>\n",
       "      <td>0.168981</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.134806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.654700</td>\n",
       "      <td>3.474194</td>\n",
       "      <td>0.154858</td>\n",
       "      <td>0.011422</td>\n",
       "      <td>0.128273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.494800</td>\n",
       "      <td>3.402363</td>\n",
       "      <td>0.154788</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>0.133270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.459200</td>\n",
       "      <td>3.359034</td>\n",
       "      <td>0.175040</td>\n",
       "      <td>0.019146</td>\n",
       "      <td>0.144857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.405700</td>\n",
       "      <td>3.356410</td>\n",
       "      <td>0.162733</td>\n",
       "      <td>0.015404</td>\n",
       "      <td>0.131585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.325000</td>\n",
       "      <td>3.300848</td>\n",
       "      <td>0.183403</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>0.151442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.192100</td>\n",
       "      <td>3.288285</td>\n",
       "      <td>0.171965</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>0.146678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.071900</td>\n",
       "      <td>3.276158</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.137622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.025300</td>\n",
       "      <td>3.246735</td>\n",
       "      <td>0.157789</td>\n",
       "      <td>0.019976</td>\n",
       "      <td>0.130194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>3.243079</td>\n",
       "      <td>0.161465</td>\n",
       "      <td>0.015963</td>\n",
       "      <td>0.127630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.869000</td>\n",
       "      <td>3.227139</td>\n",
       "      <td>0.153968</td>\n",
       "      <td>0.020957</td>\n",
       "      <td>0.128770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.844800</td>\n",
       "      <td>3.213588</td>\n",
       "      <td>0.161267</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.134366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.823700</td>\n",
       "      <td>3.226215</td>\n",
       "      <td>0.138906</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>0.118921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.924500</td>\n",
       "      <td>3.174587</td>\n",
       "      <td>0.169453</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>0.142851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.710900</td>\n",
       "      <td>3.196889</td>\n",
       "      <td>0.161982</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.134463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.713700</td>\n",
       "      <td>3.155391</td>\n",
       "      <td>0.164991</td>\n",
       "      <td>0.022767</td>\n",
       "      <td>0.145865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.587100</td>\n",
       "      <td>3.201681</td>\n",
       "      <td>0.195683</td>\n",
       "      <td>0.020477</td>\n",
       "      <td>0.164975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.651400</td>\n",
       "      <td>3.175125</td>\n",
       "      <td>0.169521</td>\n",
       "      <td>0.020409</td>\n",
       "      <td>0.141613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.447500</td>\n",
       "      <td>3.168338</td>\n",
       "      <td>0.184898</td>\n",
       "      <td>0.036531</td>\n",
       "      <td>0.153799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.397300</td>\n",
       "      <td>3.139604</td>\n",
       "      <td>0.172370</td>\n",
       "      <td>0.030053</td>\n",
       "      <td>0.142652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.408300</td>\n",
       "      <td>3.216015</td>\n",
       "      <td>0.148565</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.127903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.436100</td>\n",
       "      <td>3.207298</td>\n",
       "      <td>0.157001</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>0.139586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.271100</td>\n",
       "      <td>3.190069</td>\n",
       "      <td>0.168646</td>\n",
       "      <td>0.023007</td>\n",
       "      <td>0.141903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.307600</td>\n",
       "      <td>3.179719</td>\n",
       "      <td>0.174571</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>0.148356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.349600</td>\n",
       "      <td>3.171647</td>\n",
       "      <td>0.154624</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.137984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.308700</td>\n",
       "      <td>3.183230</td>\n",
       "      <td>0.190968</td>\n",
       "      <td>0.034428</td>\n",
       "      <td>0.160499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>2.210400</td>\n",
       "      <td>3.175599</td>\n",
       "      <td>0.200140</td>\n",
       "      <td>0.031723</td>\n",
       "      <td>0.168526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.294400</td>\n",
       "      <td>3.213566</td>\n",
       "      <td>0.174214</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>0.145790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>2.129000</td>\n",
       "      <td>3.143612</td>\n",
       "      <td>0.187161</td>\n",
       "      <td>0.033127</td>\n",
       "      <td>0.150840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>2.106700</td>\n",
       "      <td>3.181538</td>\n",
       "      <td>0.183741</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.153815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>2.127400</td>\n",
       "      <td>3.196949</td>\n",
       "      <td>0.202487</td>\n",
       "      <td>0.040666</td>\n",
       "      <td>0.163037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>2.043000</td>\n",
       "      <td>3.212136</td>\n",
       "      <td>0.186685</td>\n",
       "      <td>0.034747</td>\n",
       "      <td>0.158986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.981200</td>\n",
       "      <td>3.227640</td>\n",
       "      <td>0.193252</td>\n",
       "      <td>0.031024</td>\n",
       "      <td>0.157720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>2.031300</td>\n",
       "      <td>3.254945</td>\n",
       "      <td>0.179373</td>\n",
       "      <td>0.025386</td>\n",
       "      <td>0.143468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>2.093200</td>\n",
       "      <td>3.212796</td>\n",
       "      <td>0.190331</td>\n",
       "      <td>0.032288</td>\n",
       "      <td>0.160424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.987800</td>\n",
       "      <td>3.250369</td>\n",
       "      <td>0.198535</td>\n",
       "      <td>0.041634</td>\n",
       "      <td>0.166990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>2.026600</td>\n",
       "      <td>3.275344</td>\n",
       "      <td>0.196604</td>\n",
       "      <td>0.036055</td>\n",
       "      <td>0.161430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.934900</td>\n",
       "      <td>3.233510</td>\n",
       "      <td>0.190879</td>\n",
       "      <td>0.034279</td>\n",
       "      <td>0.159205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>2.042900</td>\n",
       "      <td>3.253694</td>\n",
       "      <td>0.191669</td>\n",
       "      <td>0.039705</td>\n",
       "      <td>0.154120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>1.911800</td>\n",
       "      <td>3.281581</td>\n",
       "      <td>0.198593</td>\n",
       "      <td>0.046867</td>\n",
       "      <td>0.159395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>1.833500</td>\n",
       "      <td>3.312561</td>\n",
       "      <td>0.172894</td>\n",
       "      <td>0.035948</td>\n",
       "      <td>0.153218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>1.835400</td>\n",
       "      <td>3.323750</td>\n",
       "      <td>0.189429</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>0.153358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.955300</td>\n",
       "      <td>3.308216</td>\n",
       "      <td>0.199693</td>\n",
       "      <td>0.054616</td>\n",
       "      <td>0.163557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>1.857200</td>\n",
       "      <td>3.290040</td>\n",
       "      <td>0.202823</td>\n",
       "      <td>0.040462</td>\n",
       "      <td>0.164531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>1.843300</td>\n",
       "      <td>3.303782</td>\n",
       "      <td>0.190610</td>\n",
       "      <td>0.039341</td>\n",
       "      <td>0.157845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>1.896100</td>\n",
       "      <td>3.315783</td>\n",
       "      <td>0.202014</td>\n",
       "      <td>0.038836</td>\n",
       "      <td>0.157377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>1.875200</td>\n",
       "      <td>3.328073</td>\n",
       "      <td>0.194897</td>\n",
       "      <td>0.033122</td>\n",
       "      <td>0.161899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.779000</td>\n",
       "      <td>3.304198</td>\n",
       "      <td>0.189207</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>0.146533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>1.689800</td>\n",
       "      <td>3.347327</td>\n",
       "      <td>0.193286</td>\n",
       "      <td>0.038134</td>\n",
       "      <td>0.161611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>1.764200</td>\n",
       "      <td>3.355862</td>\n",
       "      <td>0.194431</td>\n",
       "      <td>0.038530</td>\n",
       "      <td>0.162673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>1.694400</td>\n",
       "      <td>3.308818</td>\n",
       "      <td>0.193821</td>\n",
       "      <td>0.039717</td>\n",
       "      <td>0.156877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>1.655000</td>\n",
       "      <td>3.320247</td>\n",
       "      <td>0.203389</td>\n",
       "      <td>0.048109</td>\n",
       "      <td>0.172104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.739900</td>\n",
       "      <td>3.341687</td>\n",
       "      <td>0.197089</td>\n",
       "      <td>0.036919</td>\n",
       "      <td>0.167927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>1.690400</td>\n",
       "      <td>3.310413</td>\n",
       "      <td>0.205244</td>\n",
       "      <td>0.039146</td>\n",
       "      <td>0.164641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>1.738400</td>\n",
       "      <td>3.325481</td>\n",
       "      <td>0.206069</td>\n",
       "      <td>0.050386</td>\n",
       "      <td>0.169780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>1.735200</td>\n",
       "      <td>3.325193</td>\n",
       "      <td>0.200781</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>0.162113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>1.704600</td>\n",
       "      <td>3.363983</td>\n",
       "      <td>0.214278</td>\n",
       "      <td>0.046446</td>\n",
       "      <td>0.177347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.683600</td>\n",
       "      <td>3.352828</td>\n",
       "      <td>0.202005</td>\n",
       "      <td>0.042291</td>\n",
       "      <td>0.162788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>1.657700</td>\n",
       "      <td>3.354678</td>\n",
       "      <td>0.219246</td>\n",
       "      <td>0.045269</td>\n",
       "      <td>0.172300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>1.659300</td>\n",
       "      <td>3.408356</td>\n",
       "      <td>0.210582</td>\n",
       "      <td>0.044723</td>\n",
       "      <td>0.172211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>1.634500</td>\n",
       "      <td>3.394988</td>\n",
       "      <td>0.201523</td>\n",
       "      <td>0.034804</td>\n",
       "      <td>0.168436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>1.526000</td>\n",
       "      <td>3.360427</td>\n",
       "      <td>0.209316</td>\n",
       "      <td>0.042679</td>\n",
       "      <td>0.170539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.652800</td>\n",
       "      <td>3.367575</td>\n",
       "      <td>0.199549</td>\n",
       "      <td>0.046299</td>\n",
       "      <td>0.165168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>1.589000</td>\n",
       "      <td>3.385140</td>\n",
       "      <td>0.198895</td>\n",
       "      <td>0.047455</td>\n",
       "      <td>0.164964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>1.642600</td>\n",
       "      <td>3.391010</td>\n",
       "      <td>0.196366</td>\n",
       "      <td>0.051379</td>\n",
       "      <td>0.161246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>1.557400</td>\n",
       "      <td>3.345020</td>\n",
       "      <td>0.185450</td>\n",
       "      <td>0.043271</td>\n",
       "      <td>0.157675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>1.812400</td>\n",
       "      <td>3.392477</td>\n",
       "      <td>0.200175</td>\n",
       "      <td>0.049127</td>\n",
       "      <td>0.169724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.644000</td>\n",
       "      <td>3.363678</td>\n",
       "      <td>0.189387</td>\n",
       "      <td>0.047640</td>\n",
       "      <td>0.153708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>1.672500</td>\n",
       "      <td>3.382315</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>0.048495</td>\n",
       "      <td>0.170626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>1.620700</td>\n",
       "      <td>3.362777</td>\n",
       "      <td>0.199255</td>\n",
       "      <td>0.043506</td>\n",
       "      <td>0.165064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>1.706200</td>\n",
       "      <td>3.367263</td>\n",
       "      <td>0.202540</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>0.167071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>1.577100</td>\n",
       "      <td>3.392642</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.165732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.671000</td>\n",
       "      <td>3.396993</td>\n",
       "      <td>0.193014</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.158318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>1.640400</td>\n",
       "      <td>3.364347</td>\n",
       "      <td>0.189952</td>\n",
       "      <td>0.044797</td>\n",
       "      <td>0.165320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>1.689900</td>\n",
       "      <td>3.402543</td>\n",
       "      <td>0.187887</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>0.156542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>1.567300</td>\n",
       "      <td>3.399815</td>\n",
       "      <td>0.199816</td>\n",
       "      <td>0.047425</td>\n",
       "      <td>0.167733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>1.748900</td>\n",
       "      <td>3.360578</td>\n",
       "      <td>0.201884</td>\n",
       "      <td>0.042592</td>\n",
       "      <td>0.169479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Experiment 3 training completed successfully!\n",
      "Final training loss: 2.3541\n",
      " Experiment 3 achieved target training loss!\n",
      "\n",
      " Experiment 3 training phase completed!\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning Setup and Training\n",
    "import os\n",
    "from typing import Union, Tuple, Optional\n",
    "\n",
    "# Disable wandb reporting (set environment variables only)\n",
    "os.environ.update({\n",
    "    \"WANDB_SILENT\": \"true\",\n",
    "    \"WANDB_DISABLED\": \"true\",\n",
    "    \"WANDB_MODE\": \"disabled\"\n",
    "})\n",
    "\n",
    "# EXPERIMENT 3: Further optimized configuration for maximum convergence\n",
    "TRAINING_CONFIG = {\n",
    "    \"epochs\": 40,  # Increased from 25 to 40 for maximum convergence\n",
    "    \"learning_rate\": 5e-5,  # Sweet spot between 3e-5 and higher rates\n",
    "    \"batch_size\": 8 if device.type == 'cuda' else 4,  # Optimized batch size\n",
    "    \"gradient_accumulation_steps\": 2,  # Maintain effective batch size\n",
    "    \"warmup_steps\": 250,  # Increased warmup for better stability\n",
    "    \"eval_steps\": 30,  # Evaluation frequency\n",
    "    \"save_steps\": 60,  # Save checkpoints (must be multiple of eval_steps)\n",
    "    \"logging_steps\": 10  # Detailed logging\n",
    "}\n",
    "\n",
    "# Enhanced generation configuration for better responses\n",
    "GENERATION_CONFIG = {\n",
    "    \"max_new_tokens\": 150,  # Increased for more detailed responses\n",
    "    \"min_length\": 30,  # Increased minimum length\n",
    "    \"num_beams\": 8,  # Increased beam search\n",
    "    \"early_stopping\": True,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,  # Slightly reduced for more focused responses\n",
    "    \"top_p\": 0.9,  # Increased for better diversity\n",
    "    \"no_repeat_ngram_size\": 3,\n",
    "    \"repetition_penalty\": 1.4,  # Increased to reduce repetition\n",
    "    \"length_penalty\": 1.3,  # Increased for longer responses\n",
    "    \"diversity_penalty\": 0.3  # Increased for more diverse responses\n",
    "}\n",
    "\n",
    "def clean_response_text(response: str) -> str:\n",
    "    \"\"\"Clean generated response text.\"\"\"\n",
    "    response = response.strip()\n",
    "    # Remove repetitive patterns\n",
    "    response = re.sub(r'\\b(\\w+(?:\\s+\\w+){0,3})\\s*;\\s*\\1(?:\\s*;\\s*\\1)*', r'\\1', response)\n",
    "    response = re.sub(r'\\b(\\w+(?:\\s+\\w+){0,2})\\s+\\1\\b.*', r'\\1', response)\n",
    "    response = re.sub(r';+', ';', response)\n",
    "    response = re.sub(r'\\s+', ' ', response)\n",
    "    return response\n",
    "\n",
    "def compute_metrics(eval_pred) -> Dict[str, float]:\n",
    "    \"\"\"Compute ROUGE metrics for evaluation.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    \n",
    "    if not isinstance(predictions, np.ndarray):\n",
    "        predictions = np.array(predictions)\n",
    "    \n",
    "    if predictions.ndim == 3:\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    vocab_size = len(tokenizer)\n",
    "    predictions = np.clip(predictions, 0, vocab_size - 1)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    try:\n",
    "        decoded_preds = []\n",
    "        decoded_labels = []\n",
    "        \n",
    "        for pred_seq, label_seq in zip(predictions, labels):\n",
    "            # Filter valid tokens\n",
    "            valid_pred_tokens = [token for token in pred_seq if 0 <= token < vocab_size]\n",
    "            valid_label_tokens = [token for token in label_seq if 0 <= token < vocab_size]\n",
    "            \n",
    "            try:\n",
    "                pred_text = tokenizer.decode(valid_pred_tokens, skip_special_tokens=True)\n",
    "                label_text = tokenizer.decode(valid_label_tokens, skip_special_tokens=True)\n",
    "                decoded_preds.append(pred_text.strip())\n",
    "                decoded_labels.append(label_text.strip())\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to decode sequence: {e}\")\n",
    "                decoded_preds.append(\"no answer\")\n",
    "                decoded_labels.append(\"no answer\")\n",
    "        \n",
    "        # Handle empty predictions\n",
    "        decoded_preds = [pred if pred else \"no answer\" for pred in decoded_preds]\n",
    "        decoded_labels = [label if label else \"no answer\" for label in decoded_labels]\n",
    "        \n",
    "        # Compute ROUGE scores\n",
    "        result = rouge.compute(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "            use_stemmer=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"rouge1\": result[\"rouge1\"],\n",
    "            \"rouge2\": result[\"rouge2\"],\n",
    "            \"rougeL\": result[\"rougeL\"]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Metrics computation failed: {e}\")\n",
    "        return {\"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0}\n",
    "\n",
    "class AdvancedT5Trainer(Trainer):\n",
    "    \"\"\"Enhanced T5 Trainer with improved generation capabilities.\"\"\"\n",
    "    \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only: bool, ignore_keys=None):\n",
    "        \"\"\"Enhanced prediction step with better generation settings.\"\"\"\n",
    "        if prediction_loss_only:\n",
    "            return super().prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n",
    "        \n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs.get(\"attention_mask\", None)\n",
    "        labels = inputs.get(\"labels\", None)\n",
    "        \n",
    "        # Enhanced generation config\n",
    "        eval_config = GENERATION_CONFIG.copy()\n",
    "        tokenizer_ref = self.processing_class or self.tokenizer\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                pad_token_id=tokenizer_ref.pad_token_id,\n",
    "                eos_token_id=tokenizer_ref.eos_token_id,\n",
    "                bos_token_id=getattr(tokenizer_ref, 'bos_token_id', None),\n",
    "                **eval_config\n",
    "            )\n",
    "        \n",
    "        # Ensure valid token range\n",
    "        vocab_size = len(tokenizer_ref)\n",
    "        generated_tokens = torch.clamp(generated_tokens, 0, vocab_size - 1)\n",
    "        \n",
    "        # Compute loss if needed\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "        \n",
    "        return (loss, generated_tokens, labels)\n",
    "\n",
    "# Enhanced training arguments with optimized parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(MODEL_DIR / \"flan-t5-hydroponic-checkpoints\"),\n",
    "    num_train_epochs=TRAINING_CONFIG[\"epochs\"],\n",
    "    per_device_train_batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    per_device_eval_batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    gradient_accumulation_steps=TRAINING_CONFIG[\"gradient_accumulation_steps\"],\n",
    "    warmup_steps=TRAINING_CONFIG[\"warmup_steps\"],\n",
    "    learning_rate=TRAINING_CONFIG[\"learning_rate\"],\n",
    "    weight_decay=0.02,  # Increased weight decay for better regularization\n",
    "    logging_dir=str(MODEL_DIR / \"logs\"),\n",
    "    logging_steps=TRAINING_CONFIG[\"logging_steps\"],\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=TRAINING_CONFIG[\"eval_steps\"],\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=TRAINING_CONFIG[\"save_steps\"],\n",
    "    save_total_limit=8,  # Increased to save more checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=device.type == 'cuda',\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    group_by_length=True,\n",
    "    # Additional optimization parameters\n",
    "    adam_epsilon=1e-6,  # Smaller epsilon for better optimization\n",
    "    max_grad_norm=0.5,  # Gradient clipping for stability\n",
    "    lr_scheduler_type=\"cosine\",  # Cosine learning rate schedule\n",
    "    warmup_ratio=0.1  # 10% warmup ratio\n",
    ")\n",
    "\n",
    "# Create data collator and load evaluation metric\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    pad_to_multiple_of=8 if device.type == 'cuda' else None\n",
    ")\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "print(\"EXPERIMENT 3: Training setup completed!\")\n",
    "\n",
    "print(f\"\\nðŸ”¬ Experiment 3 Configuration Summary:\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Epochs: {TRAINING_CONFIG['epochs']} (Exp1: 12 â†’ Exp2: 25 â†’ Exp3: 40)\")\n",
    "print(f\"   Learning rate: {TRAINING_CONFIG['learning_rate']} (Exp1: 1e-5 â†’ Exp2: 3e-5 â†’ Exp3: 5e-5)\")\n",
    "print(f\"   Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"   Gradient accumulation: {TRAINING_CONFIG['gradient_accumulation_steps']}\")\n",
    "print(f\"   Effective batch size: {TRAINING_CONFIG['batch_size'] * TRAINING_CONFIG['gradient_accumulation_steps']}\")\n",
    "print(f\"   Mixed precision: {device.type == 'cuda'}\")\n",
    "print(f\"   Warmup steps: {TRAINING_CONFIG['warmup_steps']} (Exp2: 200 â†’ Exp3: 250)\")\n",
    "print(f\"   Weight decay: {training_args.weight_decay}\")\n",
    "print(f\"   LR scheduler: {training_args.lr_scheduler_type}\")\n",
    "\n",
    "# Create enhanced trainer with optimized settings\n",
    "print(\"\\nCreating enhanced trainer...\")\n",
    "trainer = AdvancedT5Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(None, None)  # Use default optimizer with our custom settings\n",
    ")\n",
    "\n",
    "print(\"Training Data Summary:\")\n",
    "print(f\"   Training samples: {len(train_dataset)}\")\n",
    "print(f\"   Validation samples: {len(val_dataset)}\")\n",
    "print(f\"   Expected time: ~150-200 minutes (40 epochs on CPU)\")\n",
    "\n",
    "print(f\"\\n Experiment 3 Performance Targets:\")\n",
    "print(f\"   Training loss: < 2.5 (building on Exp2: 3.23)\")\n",
    "print(f\"   ROUGE-1: > 0.20 (building on Exp2: 0.19)\")\n",
    "print(f\"   ROUGE-2: > 0.05 (building on Exp2: 0.045)\")\n",
    "\n",
    "print(f\"\\n Starting Experiment 3 training (40 epochs)...\")\n",
    "\n",
    "# Start training with Experiment 3 parameters\n",
    "training_output = trainer.train()\n",
    "\n",
    "print(f\"\\n Experiment 3 training completed successfully!\")\n",
    "print(f\"Final training loss: {training_output.training_loss:.4f}\")\n",
    "if training_output.training_loss < 2.5:\n",
    "    print(\" Experiment 3 achieved target training loss!\")\n",
    "elif training_output.training_loss < 3.0:\n",
    "    print(\" Good progress - training loss improved\")\n",
    "else:\n",
    "    print(\"  Training loss needs more optimization\")\n",
    "\n",
    "print(f\"\\n Experiment 3 training phase completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9606e137",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc1e907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 04:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "   eval_loss: 3.2427\n",
      "   eval_rouge1: 0.1867\n",
      "   eval_rouge2: 0.0431\n",
      "   eval_rougeL: 0.1541\n",
      "\n",
      "Advanced Question Testing:\n",
      "\n",
      "1. Q: What is the optimal pH range for hydroponic lettuce and why?\n",
      "   A: EC 1.6â€“1.8; pH 5.8â€“6.2; pH 7.8â€“7.2; pH 9.0â€“10.8; pH 8.8â€“9.8; EC 2.0â€“2.8; pH 3.0â€“2.8.\n",
      "\n",
      "2. Q: How often should I change the nutrient solution and what factors affect this?\n",
      "   A: Change the nutrient solution every 1-2 weeks or as needed to maintain plant health and prevent weeds from forming in the system.\n",
      "\n",
      "3. Q: What are the best vegetables for hydroponic farming in Rwanda considering climate?\n",
      "   A: Plants with good drainage and good airflow can thrive in cooler climates like tropical rainforests or tropical dry climates such as tropical cyclones.\n",
      "\n",
      "4. Q: How do I prevent and treat root rot in hydroponic systems effectively?\n",
      "   A: Root rot is a common problem in hydroponic systems due to poor air circulation and poor airflow. Improve airflow and improve airflow to prevent root rot.\n",
      "\n",
      "5. Q: What essential nutrients do hydroponic tomatoes need for maximum yield?\n",
      "   A: EC 1.2â€“1.8; pH 5.8â€“6.2; potassium; calcium; magnesium; phosphorus; oxygen; nutrient density.\n",
      "\n",
      "6. Q: What's the difference between DWC and NFT systems for beginners?\n",
      "   A: DWC is a simple system that uses a syringe or a pump to pump water to a reservoir. NFT is more complex and requires a lot of training.\n",
      "\n",
      "7. Q: How do I maintain proper EC levels in my hydroponic nutrient solution?\n",
      "   A: Use pH 5.8â€“6.2; use EC 2.0â€“2.8; monitor EC levels regularly; maintain EC level within 1â€“2 microns.\n",
      "\n",
      "Performance Analysis:\n",
      "   Training Loss: 2.3541 (GOOD)\n",
      "   ROUGE-1: 0.1867 (NEEDS IMPROVEMENT)\n",
      "   ROUGE-2: 0.0431 (NEEDS IMPROVEMENT)\n",
      "   ROUGE-L: 0.1541\n",
      "\n",
      "Response Quality Analysis:\n",
      "\n",
      "1. Q: What pH level should I maintain for hydroponic tomatoes?\n",
      "   A: EC 1.2â€“1.8; pH 5.8â€“6.2; maintain EC 2.0â€“2.8; avoid overwatering and excessive EC buildup.\n",
      "   Quality: GOOD | Length: 13 | Complexity: 0.85 | Repetition: 0.15\n",
      "\n",
      "2. Q: How do I prevent algae growth in my hydroponic system?\n",
      "   A: Use a pH 5.8 or higher to prevent algae growth; use EC 1.6â€“1.8 to prevent EC deficiency.\n",
      "   Quality: GOOD | Length: 17 | Complexity: 0.82 | Repetition: 0.18\n",
      "\n",
      "3. Q: What are the signs of nutrient deficiency in hydroponic plants?\n",
      "   A: Signs of nutrient deficiency include yellowing leaves sluggish growth and low oxygen levels in the plant system.\n",
      "   Quality: EXCELLENT | Length: 17 | Complexity: 1.00 | Repetition: 0.00\n",
      "\n",
      "4. Q: How much light do hydroponic vegetables need daily?\n",
      "   A: Aim for 1â€“2 hours of light per day for best results; increase by 2â€“3 hours per day if leafy greens need more light.\n",
      "   Quality: GOOD | Length: 23 | Complexity: 0.83 | Repetition: 0.17\n",
      "\n",
      "5. Q: What's the difference between DWC and NFT hydroponic systems?\n",
      "   A: DWC is a low-cost, low-maintenance hydroponic system; NFT is more cost-effective and easier to maintain.\n",
      "   Quality: GOOD | Length: 15 | Complexity: 0.93 | Repetition: 0.07\n",
      "\n",
      "6. Q: How do I calculate the right nutrient concentration for lettuce?\n",
      "   A: Calculate nutrient concentrations based on plant size and disease severity; use a pH 6.0 or higher for leafy greens.\n",
      "   Quality: EXCELLENT | Length: 19 | Complexity: 1.00 | Repetition: 0.00\n",
      "\n",
      "7. Q: What temperature should I maintain in my hydroponic greenhouse?\n",
      "   A: Temperatures should be between 70â€“80Â°F (20â€“30Â°C) and 65â€“70Â°F (10â€“20Â°C).\n",
      "   Quality: FAIR | Length: 9 | Complexity: 1.00 | Repetition: 0.00\n",
      "\n",
      "8. Q: Which crops are most profitable for hydroponic farming in Rwanda?\n",
      "   A: Rwandan maize is one of the most profitable crops for hydroponic farming; bananas are also a popular crop in the country.\n",
      "   Quality: EXCELLENT | Length: 21 | Complexity: 0.95 | Repetition: 0.05\n",
      "\n",
      "Overall Quality Metrics:\n",
      "   Average Length: 16.8 words\n",
      "   Average Complexity: 0.92\n",
      "   Average Repetition: 0.08\n",
      "\n",
      "Final Assessment:\n",
      "   Overall Score: 65/100\n",
      "   Status: GOOD QUALITY\n",
      "   Recommendation: Suitable for testing and gradual deployment\n",
      "\n",
      "Next Steps:\n",
      "   - Continue training with lower learning rate\n",
      "   - Expand dataset with more examples\n",
      "   - Fine-tune generation parameters\n",
      "\n",
      "Evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Model Evaluation\n",
    "def generate_enhanced_response(question: str, model, tokenizer, \n",
    "                             config: Optional[Dict] = None) -> str:\n",
    "    \"\"\"Generate enhanced response with improved settings.\"\"\"\n",
    "    if config is None:\n",
    "        config = GENERATION_CONFIG\n",
    "    \n",
    "    input_text = f\"Answer this hydroponic farming question: {question}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    enhanced_config = config.copy()\n",
    "    enhanced_config.update({\n",
    "        \"max_new_tokens\": 120,\n",
    "        \"num_beams\": 6,\n",
    "        \"temperature\": 0.8,\n",
    "        \"repetition_penalty\": 1.3,\n",
    "        \"length_penalty\": 1.2\n",
    "    })\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            **enhanced_config,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return clean_response_text(response)\n",
    "\n",
    "def analyze_response_quality(response: str) -> Dict[str, Union[float, str, int]]:\n",
    "    \"\"\"Analyze response quality with multiple metrics.\"\"\"\n",
    "    words = response.split()\n",
    "    if not words:\n",
    "        return {\"repetition\": 1.0, \"quality\": \"Poor - Empty response\", \"length\": 0, \"complexity\": 0}\n",
    "    \n",
    "    unique_words = len(set(words))\n",
    "    total_words = len(words)\n",
    "    repetition_score = (total_words - unique_words) / total_words\n",
    "    complexity_score = unique_words / total_words\n",
    "    \n",
    "    # Quality assessment\n",
    "    if repetition_score < 0.1 and complexity_score > 0.7 and total_words > 15:\n",
    "        quality = \"EXCELLENT\"\n",
    "    elif repetition_score < 0.2 and complexity_score > 0.6 and total_words > 10:\n",
    "        quality = \"GOOD\"\n",
    "    elif repetition_score < 0.3 and total_words > 5:\n",
    "        quality = \"FAIR\"\n",
    "    else:\n",
    "        quality = \"POOR\"\n",
    "    \n",
    "    return {\n",
    "        \"repetition\": repetition_score,\n",
    "        \"quality\": quality,\n",
    "        \"length\": total_words,\n",
    "        \"complexity\": complexity_score\n",
    "    }\n",
    "\n",
    "def assess_model_performance(training_loss: float, rouge_scores: Dict[str, float]) -> Dict[str, str]:\n",
    "    \"\"\"Assess overall model performance.\"\"\"\n",
    "    loss_status = (\"EXCELLENT\" if training_loss < 2.0 else \n",
    "                  \"GOOD\" if training_loss < 3.0 else \"NEEDS MORE TRAINING\")\n",
    "    \n",
    "    rouge1_status = (\"EXCELLENT\" if rouge_scores['eval_rouge1'] > 0.35 else\n",
    "                    \"GOOD\" if rouge_scores['eval_rouge1'] > 0.25 else \"NEEDS IMPROVEMENT\")\n",
    "    \n",
    "    rouge2_status = (\"EXCELLENT\" if rouge_scores['eval_rouge2'] > 0.08 else\n",
    "                    \"GOOD\" if rouge_scores['eval_rouge2'] > 0.05 else \"NEEDS IMPROVEMENT\")\n",
    "    \n",
    "    return {\n",
    "        \"loss_status\": loss_status,\n",
    "        \"rouge1_status\": rouge1_status,\n",
    "        \"rouge2_status\": rouge2_status\n",
    "    }\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "for key, value in test_results.items():\n",
    "    if 'rouge' in key or 'loss' in key:\n",
    "        print(f\"   {key}: {value:.4f}\")\n",
    "\n",
    "# Advanced test questions\n",
    "ADVANCED_QUESTIONS = [\n",
    "    \"What is the optimal pH range for hydroponic lettuce and why?\",\n",
    "    \"How often should I change the nutrient solution and what factors affect this?\",\n",
    "    \"What are the best vegetables for hydroponic farming in Rwanda considering climate?\",\n",
    "    \"How do I prevent and treat root rot in hydroponic systems effectively?\",\n",
    "    \"What essential nutrients do hydroponic tomatoes need for maximum yield?\",\n",
    "    \"What's the difference between DWC and NFT systems for beginners?\",\n",
    "    \"How do I maintain proper EC levels in my hydroponic nutrient solution?\"\n",
    "]\n",
    "\n",
    "print(f\"\\nAdvanced Question Testing:\")\n",
    "model.eval()\n",
    "\n",
    "for i, question in enumerate(ADVANCED_QUESTIONS, 1):\n",
    "    try:\n",
    "        response = generate_enhanced_response(question, model, tokenizer)\n",
    "        print(f\"\\n{i}. Q: {question}\")\n",
    "        print(f\"   A: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{i}. Q: {question}\")\n",
    "        print(f\"   Error: {e}\")\n",
    "\n",
    "# Performance analysis\n",
    "performance = assess_model_performance(training_output.training_loss, test_results)\n",
    "\n",
    "print(f\"\\nPerformance Analysis:\")\n",
    "print(f\"   Training Loss: {training_output.training_loss:.4f} ({performance['loss_status']})\")\n",
    "print(f\"   ROUGE-1: {test_results['eval_rouge1']:.4f} ({performance['rouge1_status']})\")\n",
    "print(f\"   ROUGE-2: {test_results['eval_rouge2']:.4f} ({performance['rouge2_status']})\")\n",
    "print(f\"   ROUGE-L: {test_results['eval_rougeL']:.4f}\")\n",
    "\n",
    "# Comprehensive quality testing\n",
    "QUALITY_TEST_QUESTIONS = [\n",
    "    \"What pH level should I maintain for hydroponic tomatoes?\",\n",
    "    \"How do I prevent algae growth in my hydroponic system?\",\n",
    "    \"What are the signs of nutrient deficiency in hydroponic plants?\",\n",
    "    \"How much light do hydroponic vegetables need daily?\",\n",
    "    \"What's the difference between DWC and NFT hydroponic systems?\",\n",
    "    \"How do I calculate the right nutrient concentration for lettuce?\",\n",
    "    \"What temperature should I maintain in my hydroponic greenhouse?\",\n",
    "    \"Which crops are most profitable for hydroponic farming in Rwanda?\"\n",
    "]\n",
    "\n",
    "print(f\"\\nResponse Quality Analysis:\")\n",
    "quality_metrics = {\"repetition\": [], \"complexity\": [], \"length\": []}\n",
    "\n",
    "for i, question in enumerate(QUALITY_TEST_QUESTIONS, 1):\n",
    "    try:\n",
    "        response = generate_enhanced_response(question, model, tokenizer)\n",
    "        analysis = analyze_response_quality(response)\n",
    "        \n",
    "        quality_metrics[\"repetition\"].append(analysis[\"repetition\"])\n",
    "        quality_metrics[\"complexity\"].append(analysis[\"complexity\"])\n",
    "        quality_metrics[\"length\"].append(analysis[\"length\"])\n",
    "        \n",
    "        print(f\"\\n{i}. Q: {question}\")\n",
    "        print(f\"   A: {response}\")\n",
    "        print(f\"   Quality: {analysis['quality']} | Length: {analysis['length']} | \"\n",
    "              f\"Complexity: {analysis['complexity']:.2f} | Repetition: {analysis['repetition']:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n{i}. Error with question: {e}\")\n",
    "\n",
    "# Final assessment\n",
    "if quality_metrics[\"repetition\"]:\n",
    "    avg_repetition = np.mean(quality_metrics[\"repetition\"])\n",
    "    avg_complexity = np.mean(quality_metrics[\"complexity\"])\n",
    "    avg_length = np.mean(quality_metrics[\"length\"])\n",
    "    \n",
    "    print(f\"\\nOverall Quality Metrics:\")\n",
    "    print(f\"   Average Length: {avg_length:.1f} words\")\n",
    "    print(f\"   Average Complexity: {avg_complexity:.2f}\")\n",
    "    print(f\"   Average Repetition: {avg_repetition:.2f}\")\n",
    "    \n",
    "    # Calculate performance score\n",
    "    performance_score = 0\n",
    "    if training_output.training_loss < 2.0:\n",
    "        performance_score += 25\n",
    "    elif training_output.training_loss < 3.0:\n",
    "        performance_score += 15\n",
    "    \n",
    "    if test_results['eval_rouge1'] > 0.35:\n",
    "        performance_score += 25\n",
    "    elif test_results['eval_rouge1'] > 0.25:\n",
    "        performance_score += 15\n",
    "    \n",
    "    if avg_repetition < 0.2:\n",
    "        performance_score += 25\n",
    "    elif avg_repetition < 0.3:\n",
    "        performance_score += 15\n",
    "    \n",
    "    if avg_complexity > 0.7:\n",
    "        performance_score += 25\n",
    "    elif avg_complexity > 0.6:\n",
    "        performance_score += 15\n",
    "    \n",
    "    print(f\"\\nFinal Assessment:\")\n",
    "    print(f\"   Overall Score: {performance_score}/100\")\n",
    "    \n",
    "    if performance_score >= 80:\n",
    "        status = \"PRODUCTION READY\"\n",
    "        recommendation = \"Deploy immediately with confidence\"\n",
    "    elif performance_score >= 60:\n",
    "        status = \"GOOD QUALITY\"\n",
    "        recommendation = \"Suitable for testing and gradual deployment\"\n",
    "    elif performance_score >= 40:\n",
    "        status = \"MODERATE QUALITY\"\n",
    "        recommendation = \"Needs additional training or fine-tuning\"\n",
    "    else:\n",
    "        status = \"NEEDS IMPROVEMENT\"\n",
    "        recommendation = \"Requires significant improvements\"\n",
    "    \n",
    "    print(f\"   Status: {status}\")\n",
    "    print(f\"   Recommendation: {recommendation}\")\n",
    "    \n",
    "    print(f\"\\nNext Steps:\")\n",
    "    if performance_score >= 70:\n",
    "        print(f\"   - Save model and integrate with app.py\")\n",
    "        print(f\"   - Use enhanced generation settings in production\")\n",
    "        print(f\"   - Monitor user feedback and iterate\")\n",
    "    else:\n",
    "        print(f\"   - Continue training with lower learning rate\")\n",
    "        print(f\"   - Expand dataset with more examples\")\n",
    "        print(f\"   - Fine-tune generation parameters\")\n",
    "\n",
    "print(f\"\\nEvaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e07ee5",
   "metadata": {},
   "source": [
    "## 9. Save the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ecdffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing memory...\n",
      "Saving fine-tuned model...\n",
      "SUCCESS: Fine-tuned model (final) saved to: c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\trained_model\\flan-t5-hydroponic-final\n",
      "SUCCESS: Fine-tuned model (app compatible) saved to: c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\trained_model\n",
      "Model info saved to: c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\trained_model\\model_info.json\n",
      "Generation config saved to: c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\trained_model\\generation_config.json\n",
      "\n",
      "Model Saving Summary:\n",
      "Model Locations:\n",
      "   Final model: c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\trained_model\\flan-t5-hydroponic-final\n",
      "   App-ready model: c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\trained_model\n",
      "\n",
      "Model Performance Summary:\n",
      "   Training Loss: 2.3541\n",
      "   Test ROUGE-1: 0.1867\n",
      "   Test ROUGE-2: 0.0431\n",
      "   Test ROUGE-L: 0.1541\n",
      "\n",
      "Ready for deployment!\n",
      "   Use the model in c:\\Users\\HP\\Desktop\\ALU\\Farmsmart_growmate_chatbot\\trained_model for your application\n",
      "   Reference generation_config.json for optimal settings\n",
      "Memory cleaned and model saving completed!\n"
     ]
    }
   ],
   "source": [
    "# Save Fine-tuned Model\n",
    "import gc\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU and system memory.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def save_model_safely(model, tokenizer, save_path: Path, description: str) -> bool:\n",
    "    \"\"\"Save model and tokenizer with error handling.\"\"\"\n",
    "    try:\n",
    "        save_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save with safe_serialization=False for Windows compatibility\n",
    "        model.save_pretrained(save_path, safe_serialization=False)\n",
    "        tokenizer.save_pretrained(save_path)\n",
    "        \n",
    "        print(f\"SUCCESS: {description} saved to: {save_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to save {description}: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_model_info(model_name: str, training_config: Dict, \n",
    "                     training_results: Dict, test_results: Dict) -> Dict:\n",
    "    \"\"\"Create comprehensive model information.\"\"\"\n",
    "    return {\n",
    "        \"model_info\": {\n",
    "            \"base_model\": model_name,\n",
    "            \"model_type\": \"FLAN-T5-base fine-tuned for hydroponic farming\",\n",
    "            \"creation_date\": datetime.now().isoformat(),\n",
    "            \"pytorch_version\": torch.__version__\n",
    "        },\n",
    "        \"dataset_info\": {\n",
    "            \"training_samples\": len(train_dataset),\n",
    "            \"validation_samples\": len(val_dataset),\n",
    "            \"test_samples\": len(test_dataset),\n",
    "            \"max_input_length\": MAX_INPUT_LENGTH,\n",
    "            \"max_target_length\": MAX_TARGET_LENGTH\n",
    "        },\n",
    "        \"training_config\": training_config,\n",
    "        \"performance_metrics\": {\n",
    "            \"final_training_loss\": training_results.training_loss,\n",
    "            \"test_rouge1\": test_results['eval_rouge1'],\n",
    "            \"test_rouge2\": test_results['eval_rouge2'],\n",
    "            \"test_rougeL\": test_results['eval_rougeL'],\n",
    "            \"test_loss\": test_results['eval_loss']\n",
    "        },\n",
    "        \"generation_config\": GENERATION_CONFIG,\n",
    "        \"usage_instructions\": {\n",
    "            \"input_format\": \"Answer this hydroponic farming question: {question}\",\n",
    "            \"recommended_max_length\": 512,\n",
    "            \"recommended_generation_config\": GENERATION_CONFIG\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Clear memory before saving\n",
    "print(\"Clearing memory...\")\n",
    "clear_memory()\n",
    "\n",
    "# Define save paths\n",
    "final_model_path = MODEL_DIR / \"flan-t5-hydroponic-final\"\n",
    "main_model_path = BASE_DIR / \"trained_model\"\n",
    "\n",
    "print(f\"Saving fine-tuned model...\")\n",
    "\n",
    "# Save to final model directory\n",
    "success_final = save_model_safely(\n",
    "    model, tokenizer, final_model_path, \n",
    "    \"Fine-tuned model (final)\"\n",
    ")\n",
    "\n",
    "# Save to main directory for app.py compatibility\n",
    "success_main = save_model_safely(\n",
    "    model, tokenizer, main_model_path,\n",
    "    \"Fine-tuned model (app compatible)\"\n",
    ")\n",
    "\n",
    "# Create and save model information\n",
    "if success_main:\n",
    "    try:\n",
    "        model_info = create_model_info(\n",
    "            MODEL_NAME, TRAINING_CONFIG, \n",
    "            training_output, test_results\n",
    "        )\n",
    "        \n",
    "        info_file = main_model_path / \"model_info.json\"\n",
    "        with open(info_file, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(model_info, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Model info saved to: {info_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not save model info: {e}\")\n",
    "\n",
    "# Save generation config separately for easy access\n",
    "try:\n",
    "    config_file = main_model_path / \"generation_config.json\"\n",
    "    with open(config_file, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(GENERATION_CONFIG, f, indent=2)\n",
    "    \n",
    "    print(f\"Generation config saved to: {config_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not save generation config: {e}\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\nModel Saving Summary:\")\n",
    "print(f\"Model Locations:\")\n",
    "if success_final:\n",
    "    print(f\"   Final model: {final_model_path}\")\n",
    "if success_main:\n",
    "    print(f\"   App-ready model: {main_model_path}\")\n",
    "\n",
    "print(f\"\\nModel Performance Summary:\")\n",
    "print(f\"   Training Loss: {training_output.training_loss:.4f}\")\n",
    "print(f\"   Test ROUGE-1: {test_results['eval_rouge1']:.4f}\")\n",
    "print(f\"   Test ROUGE-2: {test_results['eval_rouge2']:.4f}\")\n",
    "print(f\"   Test ROUGE-L: {test_results['eval_rougeL']:.4f}\")\n",
    "\n",
    "print(f\"\\nReady for deployment!\")\n",
    "print(f\"   Use the model in {main_model_path} for your application\")\n",
    "print(f\"   Reference generation_config.json for optimal settings\")\n",
    "\n",
    "# Clean up memory one more time\n",
    "clear_memory()\n",
    "print(f\"Memory cleaned and model saving completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
